{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.3.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting PyYAML>=5.3 (from langchain)\n",
      "  Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl.metadata (2.1 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl.metadata (9.9 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl.metadata (7.8 kB)\n",
      "Collecting langchain-core<0.4.0,>=0.3.10 (from langchain)\n",
      "  Downloading langchain_core-0.3.10-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting langchain-text-splitters<0.4.0,>=0.3.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.3.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.135-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<2,>=1 (from langchain)\n",
      "  Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl.metadata (61 kB)\n",
      "Collecting pydantic<3.0.0,>=2.7.4 (from langchain)\n",
      "  Downloading pydantic-2.9.2-py3-none-any.whl.metadata (149 kB)\n",
      "Collecting requests<3,>=2 (from langchain)\n",
      "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting attrs>=17.3.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading attrs-24.2.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl.metadata (5.1 kB)\n",
      "Collecting yarl<2.0,>=1.12.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.15.3-cp311-cp311-win_amd64.whl.metadata (59 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.4.0,>=0.3.10->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain) (4.12.2)\n",
      "Collecting httpx<1,>=0.23.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.7-cp311-none-win_amd64.whl.metadata (51 kB)\n",
      "Collecting requests-toolbelt<2.0.0,>=1.0.0 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.23.4 (from pydantic<3.0.0,>=2.7.4->langchain)\n",
      "  Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl.metadata (6.7 kB)\n",
      "Collecting charset-normalizer<4,>=2 (from requests<3,>=2->langchain)\n",
      "  Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl.metadata (34 kB)\n",
      "Collecting idna<4,>=2.5 (from requests<3,>=2->langchain)\n",
      "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2->langchain)\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl.metadata (6.5 kB)\n",
      "Collecting certifi>=2017.4.17 (from requests<3,>=2->langchain)\n",
      "  Downloading certifi-2024.8.30-py3-none-any.whl.metadata (2.2 kB)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl.metadata (3.9 kB)\n",
      "Collecting anyio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading anyio-4.6.2.post1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading httpcore-1.0.6-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting sniffio (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
      "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain)\n",
      "  Downloading jsonpointer-3.0.0-py2.py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting propcache>=0.2.0 (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl.metadata (7.9 kB)\n",
      "Downloading langchain-0.3.3-py3-none-any.whl (1.0 MB)\n",
      "   ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "   ---------------------------------------- 1.0/1.0 MB 5.9 MB/s eta 0:00:00\n",
      "Downloading aiohttp-3.10.10-cp311-cp311-win_amd64.whl (381 kB)\n",
      "Downloading langchain_core-0.3.10-py3-none-any.whl (404 kB)\n",
      "Downloading langchain_text_splitters-0.3.0-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.135-py3-none-any.whl (295 kB)\n",
      "Downloading numpy-1.26.4-cp311-cp311-win_amd64.whl (15.8 MB)\n",
      "   ---------------------------------------- 0.0/15.8 MB ? eta -:--:--\n",
      "   --- ------------------------------------ 1.3/15.8 MB 6.7 MB/s eta 0:00:03\n",
      "   ------- -------------------------------- 3.1/15.8 MB 7.4 MB/s eta 0:00:02\n",
      "   ----------- ---------------------------- 4.5/15.8 MB 7.3 MB/s eta 0:00:02\n",
      "   --------------- ------------------------ 6.0/15.8 MB 7.5 MB/s eta 0:00:02\n",
      "   ------------------- -------------------- 7.6/15.8 MB 7.3 MB/s eta 0:00:02\n",
      "   ----------------------- ---------------- 9.2/15.8 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------------- ------------ 11.0/15.8 MB 7.6 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 13.1/15.8 MB 7.8 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 14.2/15.8 MB 7.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  15.7/15.8 MB 7.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 15.8/15.8 MB 7.3 MB/s eta 0:00:00\n",
      "Downloading pydantic-2.9.2-py3-none-any.whl (434 kB)\n",
      "Downloading pydantic_core-2.23.4-cp311-none-win_amd64.whl (1.9 MB)\n",
      "   ---------------------------------------- 0.0/1.9 MB ? eta -:--:--\n",
      "   -------------------------------- ------- 1.6/1.9 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.9/1.9 MB 7.6 MB/s eta 0:00:00\n",
      "Downloading PyYAML-6.0.2-cp311-cp311-win_amd64.whl (161 kB)\n",
      "Downloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
      "Downloading SQLAlchemy-2.0.36-cp311-cp311-win_amd64.whl (2.1 MB)\n",
      "   ---------------------------------------- 0.0/2.1 MB ? eta -:--:--\n",
      "   ------------------------------ --------- 1.6/2.1 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.1/2.1 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiohappyeyeballs-2.4.3-py3-none-any.whl (14 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading attrs-24.2.0-py3-none-any.whl (63 kB)\n",
      "Downloading certifi-2024.8.30-py3-none-any.whl (167 kB)\n",
      "Downloading charset_normalizer-3.4.0-cp311-cp311-win_amd64.whl (101 kB)\n",
      "Downloading frozenlist-1.4.1-cp311-cp311-win_amd64.whl (50 kB)\n",
      "Downloading greenlet-3.1.1-cp311-cp311-win_amd64.whl (298 kB)\n",
      "Downloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
      "Downloading httpcore-1.0.6-py3-none-any.whl (78 kB)\n",
      "Downloading idna-3.10-py3-none-any.whl (70 kB)\n",
      "Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.1.0-cp311-cp311-win_amd64.whl (28 kB)\n",
      "Downloading orjson-3.10.7-cp311-none-win_amd64.whl (137 kB)\n",
      "Downloading requests_toolbelt-1.0.0-py2.py3-none-any.whl (54 kB)\n",
      "Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "Downloading yarl-1.15.3-cp311-cp311-win_amd64.whl (84 kB)\n",
      "Downloading jsonpointer-3.0.0-py2.py3-none-any.whl (7.6 kB)\n",
      "Downloading propcache-0.2.0-cp311-cp311-win_amd64.whl (44 kB)\n",
      "Downloading anyio-4.6.2.post1-py3-none-any.whl (90 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "Installing collected packages: urllib3, tenacity, sniffio, PyYAML, pydantic-core, propcache, orjson, numpy, multidict, jsonpointer, idna, h11, greenlet, frozenlist, charset-normalizer, certifi, attrs, annotated-types, aiohappyeyeballs, yarl, SQLAlchemy, requests, pydantic, jsonpatch, httpcore, anyio, aiosignal, requests-toolbelt, httpx, aiohttp, langsmith, langchain-core, langchain-text-splitters, langchain\n",
      "Successfully installed PyYAML-6.0.2 SQLAlchemy-2.0.36 aiohappyeyeballs-2.4.3 aiohttp-3.10.10 aiosignal-1.3.1 annotated-types-0.7.0 anyio-4.6.2.post1 attrs-24.2.0 certifi-2024.8.30 charset-normalizer-3.4.0 frozenlist-1.4.1 greenlet-3.1.1 h11-0.14.0 httpcore-1.0.6 httpx-0.27.2 idna-3.10 jsonpatch-1.33 jsonpointer-3.0.0 langchain-0.3.3 langchain-core-0.3.10 langchain-text-splitters-0.3.0 langsmith-0.1.135 multidict-6.1.0 numpy-1.26.4 orjson-3.10.7 propcache-0.2.0 pydantic-2.9.2 pydantic-core-2.23.4 requests-2.32.3 requests-toolbelt-1.0.0 sniffio-1.3.1 tenacity-8.5.0 urllib3-2.2.3 yarl-1.15.3\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas\n",
      "  Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.23.2 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas)\n",
      "  Downloading pytz-2024.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.2-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.3-cp311-cp311-win_amd64.whl (11.6 MB)\n",
      "   ---------------------------------------- 0.0/11.6 MB ? eta -:--:--\n",
      "   -- ------------------------------------- 0.8/11.6 MB 8.3 MB/s eta 0:00:02\n",
      "   -------- ------------------------------- 2.4/11.6 MB 7.9 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 4.2/11.6 MB 8.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 6.0/11.6 MB 8.4 MB/s eta 0:00:01\n",
      "   -------------------------- ------------- 7.6/11.6 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 9.4/11.6 MB 8.2 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 11.3/11.6 MB 8.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 11.6/11.6 MB 7.8 MB/s eta 0:00:00\n",
      "Downloading pytz-2024.2-py2.py3-none-any.whl (508 kB)\n",
      "Downloading tzdata-2024.2-py2.py3-none-any.whl (346 kB)\n",
      "Installing collected packages: pytz, tzdata, pandas\n",
      "Successfully installed pandas-2.2.3 pytz-2024.2 tzdata-2024.2\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openai\n",
      "  Downloading openai-1.51.2-py3-none-any.whl.metadata (24 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from openai) (4.6.2.post1)\n",
      "Collecting distro<2,>=1.7.0 (from openai)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from openai) (0.27.2)\n",
      "Collecting jiter<1,>=0.4.0 (from openai)\n",
      "  Downloading jiter-0.6.1-cp311-none-win_amd64.whl.metadata (5.3 kB)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from openai) (2.9.2)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from openai) (1.3.1)\n",
      "Collecting tqdm>4 (from openai)\n",
      "  Downloading tqdm-4.66.5-py3-none-any.whl.metadata (57 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.11 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from openai) (4.12.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from httpx<1,>=0.23.0->openai) (1.0.6)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from pydantic<3,>=1.9.0->openai) (2.23.4)\n",
      "Requirement already satisfied: colorama in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from tqdm>4->openai) (0.4.6)\n",
      "Downloading openai-1.51.2-py3-none-any.whl (383 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading jiter-0.6.1-cp311-none-win_amd64.whl (201 kB)\n",
      "Downloading tqdm-4.66.5-py3-none-any.whl (78 kB)\n",
      "Installing collected packages: tqdm, jiter, distro, openai\n",
      "Successfully installed distro-1.9.0 jiter-0.6.1 openai-1.51.2 tqdm-4.66.5\n"
     ]
    }
   ],
   "source": [
    "!pip install openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n"
     ]
    }
   ],
   "source": [
    "!pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain-community\n",
      "  Downloading langchain_community-0.3.2-py3-none-any.whl.metadata (2.8 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (6.0.2)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (2.0.36)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (3.10.10)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain-community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.4.0,>=0.3.3 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (0.3.3)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.10 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (0.3.10)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (0.1.135)\n",
      "Requirement already satisfied: numpy<2,>=1 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (1.26.4)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n",
      "  Downloading pydantic_settings-2.5.2-py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (2.32.3)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-community) (8.5.0)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.4.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.2.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.12.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.15.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading marshmallow-3.22.0-py3-none-any.whl.metadata (7.2 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.4.0,>=0.3.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain<0.4.0,>=0.3.3->langchain-community) (2.9.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langchain-core<0.4.0,>=0.3.10->langchain-community) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (0.27.2)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (3.10.7)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain-community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from requests<3,>=2->langchain-community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from requests<3,>=2->langchain-community) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from requests<3,>=2->langchain-community) (2024.8.30)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.1.1)\n",
      "Requirement already satisfied: anyio in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (4.6.2.post1)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.0.6)\n",
      "Requirement already satisfied: sniffio in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.2.0,>=0.1.125->langchain-community) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.10->langchain-community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<0.4.0,>=0.3.3->langchain-community) (2.23.4)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\anaconda3\\envs\\mcq_gen\\lib\\site-packages (from yarl<2.0,>=1.12.0->aiohttp<4.0.0,>=3.8.3->langchain-community) (0.2.0)\n",
      "Downloading langchain_community-0.3.2-py3-none-any.whl (2.4 MB)\n",
      "   ---------------------------------------- 0.0/2.4 MB ? eta -:--:--\n",
      "   ----------------- ---------------------- 1.0/2.4 MB 8.4 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.4/2.4 MB 7.1 MB/s eta 0:00:00\n",
      "Downloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading pydantic_settings-2.5.2-py3-none-any.whl (26 kB)\n",
      "Downloading marshmallow-3.22.0-py3-none-any.whl (49 kB)\n",
      "Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, pydantic-settings, dataclasses-json, langchain-community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain-community-0.3.2 marshmallow-3.22.0 mypy-extensions-1.0.0 pydantic-settings-2.5.2 typing-inspect-0.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain-community\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback\n",
    "from dotenv import load_dotenv\n",
    "import PyPDF2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boby.DESKTOP-06SD1DP\\AppData\\Local\\Temp\\ipykernel_9076\\4147879004.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(openai_api_key=key,model_name=\"gpt-3.5-turbo\",temperature=0.7)\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(openai_api_key=key,model_name=\"gpt-3.5-turbo\",temperature=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002CCB89AD3D0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002CCB8D53A90>, model_kwargs={}, openai_api_key='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', openai_proxy='')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"C:\\\\Users\\\\boby.DESKTOP-06SD1DP\\\\OneDrive - MSFT\\\\Final_project_Ai\\\\Response.json\",\"r\") as f:\n",
    "    RESPONSE_JSON=json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'no': '1', 'mcq': 'multiple choice questions', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '2': {'no': '2', 'mcq': 'multiple choice questions', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}, '3': {'no': '3', 'mcq': 'multiple choice questions', 'options': {'a': 'choice here', 'b': 'choice here', 'c': 'choice here', 'd': 'choice here'}, 'correct': 'correct answer'}}\n"
     ]
    }
   ],
   "source": [
    "print(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text:{text}\n",
    "You are an expert MCQ maker. Given the above text, it is your job to \\\n",
    "create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \n",
    "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. \\\n",
    "Ensure to make {number} MCQs\n",
    "RESPONSE_JSON\n",
    "{RESPONSE_JSON}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt=PromptTemplate(\n",
    "    input_variables=[\"text\",\"number\",\"subject\",\"tone\",\"RESPONSE_JSON\"],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boby.DESKTOP-06SD1DP\\AppData\\Local\\Temp\\ipykernel_9076\\3899119271.py:1: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  quiz_chain=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\",verbose=True)\n"
     ]
    }
   ],
   "source": [
    "quiz_chain=LLMChain(llm=llm,prompt=quiz_generation_prompt,output_key=\"quiz\",verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.\\\n",
    "You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
    "if the quiz is not at per with the cognitive and analytical abilities of the students,\\\n",
    "update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
    "Quiz_MCQs:\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(input_variables=[\"subject\", \"quiz\"],\n",
    "                                      template=TEMPLATE2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['quiz', 'subject'], input_types={}, partial_variables={}, template='\\nYou are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \\nif the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\\nQuiz_MCQs:\\n{quiz}\\n\\nCheck from an expert English Writer of the above quiz:\\n')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_evaluation_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain, review_chain], input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"RESPONSE_JSON\"],\n",
    "                                        output_variables=[\"quiz\", \"review\"], verbose=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SequentialChain(verbose=True, chains=[LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['RESPONSE_JSON', 'number', 'subject', 'text', 'tone'], input_types={}, partial_variables={}, template='\\nText:{text}\\nYou are an expert MCQ maker. Given the above text, it is your job to create a quiz  of {number} multiple choice questions for {subject} students in {tone} tone. \\nMake sure the questions are not repeated and check all the questions to be conforming the text as well.\\nMake sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make {number} MCQs\\nRESPONSE_JSON\\n{RESPONSE_JSON}\\n\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002CCB89AD3D0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002CCB8D53A90>, model_kwargs={}, openai_api_key='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', openai_proxy=''), output_key='quiz', output_parser=StrOutputParser(), llm_kwargs={}), LLMChain(verbose=True, prompt=PromptTemplate(input_variables=['quiz', 'subject'], input_types={}, partial_variables={}, template='\\nYou are an expert english grammarian and writer. Given a Multiple Choice Quiz for {subject} students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \\nif the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\\nQuiz_MCQs:\\n{quiz}\\n\\nCheck from an expert English Writer of the above quiz:\\n'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002CCB89AD3D0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002CCB8D53A90>, model_kwargs={}, openai_api_key='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', openai_proxy=''), output_key='review', output_parser=StrOutputParser(), llm_kwargs={})], input_variables=['text', 'number', 'subject', 'tone', 'RESPONSE_JSON'], output_variables=['quiz', 'review'])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_evaluate_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Experiment as User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=\"C:\\\\Users\\\\boby.DESKTOP-06SD1DP\\\\OneDrive - MSFT\\\\Final_project_Ai\\\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boby.DESKTOP-06SD1DP\\OneDrive - MSFT\\Final_project_Ai\\data.txt\n"
     ]
    }
   ],
   "source": [
    "print(PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(PATH,\"r\") as file:\n",
    "    TEXT=file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\'Data science is an interdisciplinary academic field[1] that uses statistics, \\nscientific computing, scientific methods, processes, algorithms and systems to extract\\nor extrapolate knowledge and insights from noisy, structured, and unstructured data.\\n[2]\\\\n\\\\nData science also integrates domain knowledge from the underlying application domain\\n(e.g., natural sciences, information technology, and medicine).\\n[3] Data science is multifaceted and can be described as a science, \\na research paradigm, a research method, a discipline, a workflow, and a profession.\\n[4]\\\\n\\\\nData science is a \"concept to unify statistics, data analysis, \\ninformatics, and their related methods\" to \"understand and analyze actual phenomena\"\\nwith data.[5] It uses techniques and theories drawn from many fields within the \\ncontext of mathematics, statistics, computer science, information science, and domain knowledge.\\n[6] However, data science is different from computer science and information science. \\nTuring Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical,\\ntheoretical, computational, and now data-driven) and asserted that \"everything about \\nscience is changing because of the impact of information technology\" \\nand the data deluge.[7][8]\\\\n\\\\nA data scientist is a professional who creates programming\\ncode and combines it with statistical knowledge to create insights from data.\\n[9]\\\\n\\\\nFoundations\\\\nData science is an interdisciplinary field[10] \\nfocused on extracting knowledge from typically large data sets and applying the \\nknowledge and insights from that data to solve problems in a wide range of \\napplication domains. The field encompasses preparing data for analysis, \\nformulating data science problems, analyzing data, developing data-driven solutions, \\nand presenting findings to inform high-level decisions in a broad range of \\napplication domains. As such, it incorporates skills from computer science, \\nstatistics, information science, mathematics, data visualization, \\ninformation visualization, data sonification, data integration, graphic design, \\ncomplex systems, communication and business.[11][12] Statistician Nathan Yau, \\ndrawing on Ben Fry, also links data science to human–computer interaction: \\nusers should be able to intuitively control and explore data.[13][14] In 2015, \\nthe American Statistical Association identified database management, statistics\\nand machine learning, and distributed and parallel systems as the three emerging\\nfoundational professional communities.[15]\\''"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Serialize the Python dictionary into a JSON-formatted string\n",
    "json.dumps(RESPONSE_JSON)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMBER=5 \n",
    "SUBJECT=\"data science\"\n",
    "TONE=\"simple\"\n",
    "RESPONSE_JSON=RESPONSE_JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\boby.DESKTOP-06SD1DP\\AppData\\Local\\Temp\\ipykernel_9076\\1279586758.py:5: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response=generate_evaluate_chain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text:'Data science is an interdisciplinary academic field[1] that uses statistics, \n",
      "scientific computing, scientific methods, processes, algorithms and systems to extract\n",
      "or extrapolate knowledge and insights from noisy, structured, and unstructured data.\n",
      "[2]\\n\\nData science also integrates domain knowledge from the underlying application domain\n",
      "(e.g., natural sciences, information technology, and medicine).\n",
      "[3] Data science is multifaceted and can be described as a science, \n",
      "a research paradigm, a research method, a discipline, a workflow, and a profession.\n",
      "[4]\\n\\nData science is a \"concept to unify statistics, data analysis, \n",
      "informatics, and their related methods\" to \"understand and analyze actual phenomena\"\n",
      "with data.[5] It uses techniques and theories drawn from many fields within the \n",
      "context of mathematics, statistics, computer science, information science, and domain knowledge.\n",
      "[6] However, data science is different from computer science and information science. \n",
      "Turing Award winner Jim Gray imagined data science as a \"fourth paradigm\" of science (empirical,\n",
      "theoretical, computational, and now data-driven) and asserted that \"everything about \n",
      "science is changing because of the impact of information technology\" \n",
      "and the data deluge.[7][8]\\n\\nA data scientist is a professional who creates programming\n",
      "code and combines it with statistical knowledge to create insights from data.\n",
      "[9]\\n\\nFoundations\\nData science is an interdisciplinary field[10] \n",
      "focused on extracting knowledge from typically large data sets and applying the \n",
      "knowledge and insights from that data to solve problems in a wide range of \n",
      "application domains. The field encompasses preparing data for analysis, \n",
      "formulating data science problems, analyzing data, developing data-driven solutions, \n",
      "and presenting findings to inform high-level decisions in a broad range of \n",
      "application domains. As such, it incorporates skills from computer science, \n",
      "statistics, information science, mathematics, data visualization, \n",
      "information visualization, data sonification, data integration, graphic design, \n",
      "complex systems, communication and business.[11][12] Statistician Nathan Yau, \n",
      "drawing on Ben Fry, also links data science to human–computer interaction: \n",
      "users should be able to intuitively control and explore data.[13][14] In 2015, \n",
      "the American Statistical Association identified database management, statistics\n",
      "and machine learning, and distributed and parallel systems as the three emerging\n",
      "foundational professional communities.[15]'\n",
      "You are an expert MCQ maker. Given the above text, it is your job to create a quiz  of 5 multiple choice questions for data science students in simple tone. \n",
      "Make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "Make sure to format your response like  RESPONSE_JSON below  and use it as a guide. Ensure to make 5 MCQs\n",
      "RESPONSE_JSON\n",
      "{\"1\": {\"no\": \"1\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"no\": \"2\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"no\": \"3\", \"mcq\": \"multiple choice questions\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "You are an expert english grammarian and writer. Given a Multiple Choice Quiz for data science students.You need to evaluate the complexity of the question and give a complete analysis of the quiz. Only use at max 50 words for complexity analysis. \n",
      "if the quiz is not at per with the cognitive and analytical abilities of the students,update the quiz questions which needs to be changed and change the tone such that it perfectly fits the student abilities\n",
      "Quiz_MCQs:\n",
      "\n",
      "{\n",
      "\"1\": {\n",
      "\"no\": \"1\",\n",
      "\"mcq\": \"What is data science?\",\n",
      "\"options\": {\n",
      "\"a\": \"A field that uses statistics and scientific computing\",\n",
      "\"b\": \"A field that studies plants and animals\",\n",
      "\"c\": \"A field that focuses on space exploration\",\n",
      "\"d\": \"A field that studies ancient civilizations\"\n",
      "},\n",
      "\"correct\": \"a\"\n",
      "},\n",
      "\"2\": {\n",
      "\"no\": \"2\",\n",
      "\"mcq\": \"What does a data scientist do?\",\n",
      "\"options\": {\n",
      "\"a\": \"Creates programming code and combines it with statistical knowledge\",\n",
      "\"b\": \"Studies the history of art\",\n",
      "\"c\": \"Analyzes weather patterns\",\n",
      "\"d\": \"Designs buildings\"\n",
      "},\n",
      "\"correct\": \"a\"\n",
      "},\n",
      "\"3\": {\n",
      "\"no\": \"3\",\n",
      "\"mcq\": \"What foundational skills are required in data science?\",\n",
      "\"options\": {\n",
      "\"a\": \"Graphic design and communication\",\n",
      "\"b\": \"Music production\",\n",
      "\"c\": \"Cooking skills\",\n",
      "\"d\": \"Car mechanics\"\n",
      "},\n",
      "\"correct\": \"a\"\n",
      "},\n",
      "\"4\": {\n",
      "\"no\": \"4\",\n",
      "\"mcq\": \"How is data science different from computer science?\",\n",
      "\"options\": {\n",
      "\"a\": \"They are the same\",\n",
      "\"b\": \"Data science focuses on extracting knowledge from data\",\n",
      "\"c\": \"Computer science is focused on studying marine life\",\n",
      "\"d\": \"Computer science is used for space exploration\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"5\": {\n",
      "\"no\": \"5\",\n",
      "\"mcq\": \"What did Jim Gray imagine data science to be?\",\n",
      "\"options\": {\n",
      "\"a\": \"A type of music genre\",\n",
      "\"b\": \"The fourth paradigm of science\",\n",
      "\"c\": \"A new form of art\",\n",
      "\"d\": \"A type of food dish\"\n",
      "},\n",
      "\"correct\": \"b\"\n",
      "}\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#https://python.langchain.com/docs/modules/model_io/llms/token_usage_tracking\n",
    "\n",
    "#How to setup Token Usage Tracking in LangChain\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\": TEXT,\n",
    "            \"number\": NUMBER,\n",
    "            \"subject\":SUBJECT,\n",
    "            \"tone\": TONE,\n",
    "            \"RESPONSE_JSON\":json.dumps(RESPONSE_JSON)\n",
    "        }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Tokens:1914\n",
      "Prompt Tokens:1373\n",
      "Completion Tokens:541\n",
      "Total Cost:0.0031414999999999998\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total Tokens:{cb.total_tokens}\")\n",
    "print(f\"Prompt Tokens:{cb.prompt_tokens}\")\n",
    "print(f\"Completion Tokens:{cb.completion_tokens}\")\n",
    "print(f\"Total Cost:{cb.total_cost}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get('quiz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n{\\n\"1\": {\\n\"no\": \"1\",\\n\"mcq\": \"What is data science?\",\\n\"options\": {\\n\"a\": \"A field that uses statistics and scientific computing\",\\n\"b\": \"A field that studies plants and animals\",\\n\"c\": \"A field that focuses on space exploration\",\\n\"d\": \"A field that studies ancient civilizations\"\\n},\\n\"correct\": \"a\"\\n},\\n\"2\": {\\n\"no\": \"2\",\\n\"mcq\": \"What does a data scientist do?\",\\n\"options\": {\\n\"a\": \"Creates programming code and combines it with statistical knowledge\",\\n\"b\": \"Studies the history of art\",\\n\"c\": \"Analyzes weather patterns\",\\n\"d\": \"Designs buildings\"\\n},\\n\"correct\": \"a\"\\n},\\n\"3\": {\\n\"no\": \"3\",\\n\"mcq\": \"What foundational skills are required in data science?\",\\n\"options\": {\\n\"a\": \"Graphic design and communication\",\\n\"b\": \"Music production\",\\n\"c\": \"Cooking skills\",\\n\"d\": \"Car mechanics\"\\n},\\n\"correct\": \"a\"\\n},\\n\"4\": {\\n\"no\": \"4\",\\n\"mcq\": \"How is data science different from computer science?\",\\n\"options\": {\\n\"a\": \"They are the same\",\\n\"b\": \"Data science focuses on extracting knowledge from data\",\\n\"c\": \"Computer science is focused on studying marine life\",\\n\"d\": \"Computer science is used for space exploration\"\\n},\\n\"correct\": \"b\"\\n},\\n\"5\": {\\n\"no\": \"5\",\\n\"mcq\": \"What did Jim Gray imagine data science to be?\",\\n\"options\": {\\n\"a\": \"A type of music genre\",\\n\"b\": \"The fourth paradigm of science\",\\n\"c\": \"A new form of art\",\\n\"d\": \"A type of food dish\"\\n},\\n\"correct\": \"b\"\\n}\\n}'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data = []\n",
    "for key, value in quiz.items():\n",
    "    mcq = value[\"mcq\"]\n",
    "    options = \" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value[\"options\"].items()\n",
    "            ]\n",
    "        )\n",
    "    correct = value[\"correct\"]\n",
    "    quiz_table_data.append({\"MCQ\": mcq, \"Choices\": options, \"Correct\": correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'What is data science?',\n",
       "  'Choices': 'a: A field that uses statistics and scientific computing | b: A field that studies plants and animals | c: A field that focuses on space exploration | d: A field that studies ancient civilizations',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'What does a data scientist do?',\n",
       "  'Choices': 'a: Creates programming code and combines it with statistical knowledge | b: Studies the history of art | c: Analyzes weather patterns | d: Designs buildings',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'What foundational skills are required in data science?',\n",
       "  'Choices': 'a: Graphic design and communication | b: Music production | c: Cooking skills | d: Car mechanics',\n",
       "  'Correct': 'a'},\n",
       " {'MCQ': 'How is data science different from computer science?',\n",
       "  'Choices': 'a: They are the same | b: Data science focuses on extracting knowledge from data | c: Computer science is focused on studying marine life | d: Computer science is used for space exploration',\n",
       "  'Correct': 'b'},\n",
       " {'MCQ': 'What did Jim Gray imagine data science to be?',\n",
       "  'Choices': 'a: A type of music genre | b: The fourth paradigm of science | c: A new form of art | d: A type of food dish',\n",
       "  'Correct': 'b'}]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCQ</th>\n",
       "      <th>Choices</th>\n",
       "      <th>Correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is data science?</td>\n",
       "      <td>a: A field that uses statistics and scientific...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What does a data scientist do?</td>\n",
       "      <td>a: Creates programming code and combines it wi...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What foundational skills are required in data ...</td>\n",
       "      <td>a: Graphic design and communication | b: Music...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How is data science different from computer sc...</td>\n",
       "      <td>a: They are the same | b: Data science focuses...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What did Jim Gray imagine data science to be?</td>\n",
       "      <td>a: A type of music genre | b: The fourth parad...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MCQ  \\\n",
       "0                              What is data science?   \n",
       "1                     What does a data scientist do?   \n",
       "2  What foundational skills are required in data ...   \n",
       "3  How is data science different from computer sc...   \n",
       "4      What did Jim Gray imagine data science to be?   \n",
       "\n",
       "                                             Choices Correct  \n",
       "0  a: A field that uses statistics and scientific...       a  \n",
       "1  a: Creates programming code and combines it wi...       a  \n",
       "2  a: Graphic design and communication | b: Music...       a  \n",
       "3  a: They are the same | b: Data science focuses...       b  \n",
       "4  a: A type of music genre | b: The fourth parad...       b  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_latex(\"Data_Science_Quiz.tex\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'09_01_2024_02_42_47'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.now().strftime('%m_%d_%Y_%H_%M_%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mcq_gen",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
